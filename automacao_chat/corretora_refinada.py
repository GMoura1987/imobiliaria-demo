import json
import sqlite3
import re
from langchain_ollama import ChatOllama
from langchain_classic.memory import ConversationBufferMemory

# --- CONFIGURA√á√ïES ---
DB_PATH = "db.sqlite3"
# Temperatura 0 para o Extrator (precis√£o l√≥gica) e 0.6 para a Ana Paula (criatividade controlada)
llm_analyst = ChatOllama(model="deepseek-r1:8b", temperature=0.0) 
llm_chat = ChatOllama(model="deepseek-r1:8b", temperature=0.3)

memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# Estado Global da Sess√£o (Persistente)
session_state = {
    "filtros": {
        "bairro": None,
        "preco_max": None,
        "quartos": None,
        "imovel_atual_id": None
    }
}

# === CAMADA DE DADOS ===

def executar_busca_db(filtros):
    """Executa a busca baseada puramente no JSON gerado pelo LLM."""
    print(f"DEBUG SQL: Buscando com filtros {filtros}") # Para voc√™ ver o que est√° acontecendo
    try:
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        query = "SELECT * FROM core_imovel WHERE 1=1"
        params = []
        
        # 1. Filtro de ID (Prioridade Total)
        if filtros.get("imovel_especifico_id"):
            cursor.execute("SELECT * FROM core_imovel WHERE id = ?", (filtros["imovel_especifico_id"],))
            res = cursor.fetchone()
            conn.close()
            return [dict(res)] if res else []

        # 2. Filtros Din√¢micos
        if filtros.get("bairro"):
            query += " AND LOWER(bairro) LIKE ?"
            params.append(f"%{filtros['bairro'].lower()}%")
            
        if filtros.get("preco_max") and filtros["preco_max"] > 0:
            query += " AND preco_aluguel <= ?"
            params.append(filtros["preco_max"])
            
        if filtros.get("quartos"):
            query += " AND quartos >= ?"
            params.append(filtros["quartos"])

        # Excluir o im√≥vel que j√° est√° sendo visto para n√£o repetir recomenda√ß√£o
        if filtros.get("excluir_id"):
             query += " AND id != ?"
             params.append(filtros["excluir_id"])

        cursor.execute(query, params)
        res = [dict(row) for row in cursor.fetchall()]
        conn.close()
        return res[:4] # Limita a 4 resultados
    except Exception as e:
        print(f"Erro SQL: {e}")
        return []

# === PASSO 1: O ANALISTA DE INTEN√á√ÉO (O C√âREBRO) ===

def extrair_intencao_json(historico, mensagem_usuario, estado_atual):
    """
    Usa o LLM para converter linguagem natural em par√¢metros de busca SQL (JSON).
    Ele raciocina sobre o contexto para atualizar, manter ou limpar filtros.
    """
    
    schema_json = """
    {
        "intencao": "BUSCA" ou "LINK_DIRETO" ou "CONVERSA",
        "imovel_especifico_id": int ou null,
        "filtros": {
            "bairro": "string ou null (null se o usuario pediu 'outros bairros')",
            "preco_max": float ou null,
            "quartos": int ou null
        },
        "explicacao": "breve motivo da mudan√ßa de filtros"
    }
    """

    prompt_analista = f"""
    Voc√™ √© um motor de busca imobili√°ria inteligente (API). 
    Sua tarefa √© analisar a conversa e gerar um JSON de filtros para consulta SQL.

    ESTADO ATUAL DOS FILTROS: {json.dumps(estado_atual)}
    
    HIST√ìRICO RECENTE:
    {historico}
    
    MENSAGEM DO USU√ÅRIO: "{mensagem_usuario}"

    REGRAS DE L√ìGICA (RACIOCINE):
    1. Se o usu√°rio mandar um link (/imovel/123), a inten√ß√£o √© "LINK_DIRETO" e o ID vai para imovel_especifico_id.
    2. Se o usu√°rio disser "t√° caro" ou "queria algo at√© 1500", ATUALIZE o 'preco_max'.
    3. Se o usu√°rio disser "tem em outros bairros?" ou "outra localiza√ß√£o", DEFINA "bairro": null (para limpar o filtro).
    4. Se o usu√°rio disser "neste bairro", MANTENHA o bairro atual.
    5. Se o usu√°rio perguntar sobre o im√≥vel atual (ex: "tem garagem?"), MANTENHA os filtros e a inten√ß√£o "CONVERSA".

    SA√çDA APENAS JSON V√ÅLIDO. NADA DE TEXTO ANTES OU DEPOIS.
    SCHEMA: {schema_json}
    """

    try:
        response = llm_analyst.invoke(prompt_analista).content
        # Limpeza para garantir que pegamos s√≥ o JSON (DeepSeek as vezes p√µe markdown)
        json_str = re.search(r'\{.*\}', response, re.DOTALL).group(0)
        return json.loads(json_str)
    except Exception as e:
        print(f"Erro no Analista JSON: {e}")
        # Fallback seguro
        return {"intencao": "CONVERSA", "filtros": estado_atual, "imovel_especifico_id": None}

# === PASSO 2: A CORRETORA (A VOZ) ===

def gerar_resposta_ana_paula(contexto_imoveis, mensagem_usuario, intencao_detectada):
    prompt_sistema = f"""
    Voc√™ √© a Ana Paula, corretora s√™nior em Juiz de Fora.
    
    DADOS REAIS DO BANCO DE DADOS (Imut√°vel):
    {contexto_imoveis}

    INSTRU√á√ïES:
    1. Se a lista de im√≥veis estiver vazia, diga a verdade: "N√£o encontrei op√ß√µes com esse perfil exato no momento". Sugira alterar os filtros.
    2. Se houver im√≥veis, apresente-os de forma sedutora mas resumida.
    3. Objetivo final: Agendar Visita.
    4. Tom de voz: Profissional, prestativa e √°gil (WhatsApp).
    
    INTEN√á√ÉO DETECTADA: {intencao_detectada}
    """
    
    historico = memory.load_memory_variables({})["chat_history"]
    prompt_final = f"{prompt_sistema}\n\nHist√≥rico: {historico}\nCliente: {mensagem_usuario}\nAna Paula:"
    
    return llm_chat.invoke(prompt_final).content.replace('Ana Paula:', '').strip()

# === FLUXO PRINCIPAL ===

def chat_pipeline(mensagem_usuario):
    global session_state
    
    # 1. Recuperar hist√≥rico para contexto
    historico = memory.load_memory_variables({})["chat_history"][-2:] # Pega apenas as 2 ultimas trocas para economizar tokens
    
    # 2. O Analista define o que buscar
    analise = extrair_intencao_json(historico, mensagem_usuario, session_state["filtros"])
    
    # Atualiza o estado da sess√£o com a nova intelig√™ncia
    novos_filtros = analise["filtros"]
    
    # L√≥gica de "Excluir o atual" se o usu√°rio estiver pedindo "outros"
    excluir_id = session_state["filtros"].get("imovel_atual_id")
    if analise["intencao"] == "BUSCA":
        novos_filtros["excluir_id"] = excluir_id
    
    # 3. Executa a busca no SQL
    imoveis_encontrados = []
    
    if analise["intencao"] == "LINK_DIRETO":
        # Se for link direto, o ID espec√≠fico prevalece
        session_state["filtros"]["imovel_atual_id"] = analise["imovel_especifico_id"]
        # Reseta filtros para focar neste imovel, mas guarda o bairro dele
        imoveis_encontrados = executar_busca_db({"imovel_especifico_id": analise["imovel_especifico_id"]})
        if imoveis_encontrados:
             novos_filtros["bairro"] = imoveis_encontrados[0]['bairro'] # Atualiza contexto de bairro

    elif analise["intencao"] == "BUSCA" or analise["intencao"] == "CONVERSA":
        imoveis_encontrados = executar_busca_db(novos_filtros)

    # Atualiza o estado global para a pr√≥xima rodada
    session_state["filtros"].update(novos_filtros)

    # 4. Formata o contexto para a Ana Paula
    texto_contexto = ""
    if imoveis_encontrados:
        texto_contexto = "IM√ìVEIS ENCONTRADOS:\n"
        for i in imoveis_encontrados:
            texto_contexto += f"- {i['titulo']} | Bairro: {i['bairro']} | R$ {i['preco_aluguel']} | Desc: {i['descricao'][:100]}...\n"
    else:
        texto_contexto = "STATUS DO SISTEMA: Nenhum im√≥vel encontrado com os filtros atuais."

    # 5. Gera a resposta final
    resposta = gerar_resposta_ana_paula(texto_contexto, mensagem_usuario, analise["intencao"])
    
    memory.save_context({"input": mensagem_usuario}, {"output": resposta})
    return resposta

# === LOOP ===
if __name__ == "__main__":
    print("--- üè† Ana Paula AI (Agentic Arch) ---")
    while True:
        voce = input("\nüë§ Voc√™: ")
        if voce.lower() in ['sair', 'parar']: break
        print(f"\nüè† Ana Paula: {chat_pipeline(voce)}")