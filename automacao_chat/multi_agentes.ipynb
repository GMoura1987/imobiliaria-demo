{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a517b348",
   "metadata": {},
   "source": [
    "+ Est√°vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import ollama\n",
    "import os\n",
    "from rapidfuzz import process\n",
    "from vanna.chromadb import ChromaDB_VectorStore\n",
    "from vanna.ollama import Ollama\n",
    "\n",
    "# ==========================================\n",
    "# AGENTE 1: ANALISTA SQL (Vers√£o Final 3.0)\n",
    "# ==========================================\n",
    "class SQLAnalyst(ChromaDB_VectorStore, Ollama):\n",
    "    def __init__(self, config=None):\n",
    "        ChromaDB_VectorStore.__init__(self, config=config)\n",
    "        Ollama.__init__(self, config=config)\n",
    "\n",
    "    def preparar_agente(self, db_path):\n",
    "        \"\"\"Conecta e treina com regras de neg√≥cio blindadas contra erros de tipagem.\"\"\"\n",
    "        self.connect_to_sqlite(db_path)\n",
    "        \n",
    "        # Extra√ß√£o de metadados reais para o Fuzzy Match\n",
    "        df_meta = self.run_sql(\"SELECT DISTINCT bairro, rua, especificacao FROM core_imovel\")\n",
    "        self.bairros = [str(x) for x in df_meta['bairro'].dropna().unique().tolist()]\n",
    "        self.ruas = [str(x) for x in df_meta['rua'].dropna().unique().tolist()]\n",
    "        self.tipos = [str(x) for x in df_meta['especificacao'].dropna().unique().tolist()]\n",
    "        self.entidades = self.bairros + self.ruas + self.tipos\n",
    "\n",
    "        if self.get_training_data().empty:\n",
    "            # Treinamento de DDL (Baseado na estrutura real do db.sqlite3)\n",
    "            self.train(ddl=\"\"\"\n",
    "            CREATE TABLE core_imovel (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT, \n",
    "                titulo VARCHAR(200), \n",
    "                descricao TEXT,\n",
    "                quartos INTEGER, \n",
    "                banheiros INTEGER, \n",
    "                garagem INTEGER, \n",
    "                area DECIMAL, \n",
    "                bairro VARCHAR(100), \n",
    "                rua VARCHAR(100), \n",
    "                preco_aluguel DECIMAL, \n",
    "                preco_iptu DECIMAL, \n",
    "                preco_condominio DECIMAL, \n",
    "                aceita_pets BOOLEAN, -- 1 para Sim, 0 para N√£o\n",
    "                especificacao VARCHAR(100) -- apartamento, casa, kitnet, studio, loft, cobertura\n",
    "            );\n",
    "            \"\"\")\n",
    "\n",
    "            # Treinamento de Regras Cr√≠ticas (Resolvendo falhas de auditoria)\n",
    "            self.train(documentation=f\"\"\"\n",
    "            - Localiza√ß√£o: Juiz de Fora, MG.\n",
    "            - REGRA DE ID: O campo 'id' √© um INTEIRO. Ex: 'im√≥vel 131' deve ser traduzido como WHERE id = 131.\n",
    "            - REGRA DE PETS: Se o cliente citar 'gato', 'cachorro' ou 'pets', use 'aceita_pets = 1'. \n",
    "            - NUNCA use LOWER() ou LIKE em colunas booleanas (aceita_pets) ou num√©ricas (pre√ßos, quartos, id).\n",
    "            - Use LOWER() apenas para colunas de texto: bairro, rua, especificacao.\n",
    "            - Custo Total = (preco_aluguel + preco_condominio + preco_iptu).\n",
    "            - NUNCA adicione filtros de pet (aceita_pets = 0) a menos que o cliente pe√ßa 'que N√ÉO aceitem pets'.\n",
    "            - Bairros em JF: {\", \".join(self.bairros)}.\n",
    "            \"\"\")\n",
    "\n",
    "    def normalizar(self, texto):\n",
    "        nfkd = unicodedata.normalize('NFKD', str(texto))\n",
    "        return \"\".join([c for c in nfkd if not unicodedata.combining(c)]).lower().strip()\n",
    "\n",
    "    def fuzzy_cleanup(self, pergunta):\n",
    "        \"\"\"Corrige a pergunta sem duplicar entidades ou alucinar bairros.\"\"\"\n",
    "        tokens = pergunta.split()\n",
    "        resultado = []\n",
    "        \n",
    "        # Mapeamento r√°pido de tokens protegidos e num√©ricos\n",
    "        for t in tokens:\n",
    "            t_norm = self.normalizar(t)\n",
    "            if t_norm.isdigit() or len(t_norm) <= 3:\n",
    "                resultado.append(t)\n",
    "                continue\n",
    "            \n",
    "            # Busca correspond√™ncia em bairros/ruas/tipos\n",
    "            match = process.extractOne(t_norm, [self.normalizar(e) for e in self.entidades], score_cutoff=90)\n",
    "            if match:\n",
    "                # Recupera o nome original com a capitaliza√ß√£o correta do banco\n",
    "                idx = [self.normalizar(e) for e in self.entidades].index(match[0])\n",
    "                entidade_real = self.entidades[idx]\n",
    "                resultado.append(entidade_real)\n",
    "            else:\n",
    "                resultado.append(t)\n",
    "        \n",
    "        pergunta_limpa = \" \".join(resultado)\n",
    "        # Inje√ß√£o sem√¢ntica para Pets se houver men√ß√£o a animais\n",
    "        if any(x in pergunta.lower() for x in [\"gato\", \"cachorro\", \"animal\"]):\n",
    "            pergunta_limpa += \" que aceita pets\"\n",
    "            \n",
    "        return pergunta_limpa\n",
    "\n",
    "    def executar_consulta(self, pergunta):\n",
    "        pergunta_limpa = self.fuzzy_cleanup(pergunta)\n",
    "        try:\n",
    "            sql = self.generate_sql(pergunta_limpa)\n",
    "            df = self.run_sql(sql)\n",
    "            return df, sql\n",
    "        except Exception as e:\n",
    "            return None, f\"Erro: {str(e)}\"\n",
    "\n",
    "# ==========================================\n",
    "# AGENTE 2: BIA (Persona Geofenced)\n",
    "# ==========================================\n",
    "class BiaPersona:\n",
    "    def __init__(self, bairros_validos, model_name='deepseek-r1:8b'):\n",
    "        self.model = model_name\n",
    "        self.bairros_validos = bairros_validos\n",
    "        self.system_prompt = f\"\"\"\n",
    "        Voc√™ √© a Bia, secret√°ria virtual de uma imobili√°ria em Juiz de Fora.\n",
    "        REGRAS:\n",
    "        1. Se o banco de dados retornar 'Vazio', n√£o invente dados. Diga que n√£o encontrou e sugira bairros como: {\", \".join(self.bairros_validos[:5])}.\n",
    "        2. Nunca use termos t√©cnicos de programa√ß√£o.\n",
    "        3. Para c√°lculos, use os valores de aluguel, IPTU e condom√≠nio fornecidos.\n",
    "        \"\"\"\n",
    "\n",
    "    def responder(self, pergunta, df):\n",
    "        contexto = df.to_dict(orient='records') if df is not None and not df.empty else \"Nenhum im√≥vel encontrado.\"\n",
    "        prompt = f\"Pergunta do Cliente: {pergunta}\\nDados Reais do Banco: {contexto}\\nBia, responda:\"\n",
    "        \n",
    "        try:\n",
    "            response = ollama.generate(model=self.model, system=self.system_prompt, prompt=prompt, options={'temperature': 0.1})\n",
    "            return response['response'].split(\"</thought>\")[-1].strip()\n",
    "        except Exception:\n",
    "            return \"Tive uma falha t√©cnica r√°pida, mas posso pesquisar outro bairro para voc√™ em JF!\"\n",
    "\n",
    "# ==========================================\n",
    "# MOTOR DE TESTES DE CONFER√äNCIA\n",
    "# ==========================================\n",
    "def bateria_de_conferencia(analista, bia):\n",
    "    testes = [\n",
    "        \"Qual o custo total do im√≥vel 131?\",              # Foco: C√°lculo e ID Inteiro\n",
    "        \"Tem cobertura no Benfica que aceita gatos?\",      # Foco: Regra de Pet Booleana\n",
    "        \"Quais casas tem no bairo Benfika?\",              # Foco: Fuzzy Match sem alucina√ß√£o\n",
    "        \"Qual o apartamento mais barato no Centro?\"       # Foco: Ordena√ß√£o e Filtro Geogr√°fico\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüìù Iniciando Testes de Confer√™ncia Final...\")\n",
    "    for i, p in enumerate(testes, 1):\n",
    "        df, sql = analista.executar_consulta(p)\n",
    "        resposta = bia.responder(p, df)\n",
    "        print(f\"\\n--- Teste {i} ---\")\n",
    "        print(f\"Pergunta: {p}\")\n",
    "        print(f\"SQL: {sql}\")\n",
    "        print(f\"Bia: {resposta}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config_sql = {\"model\": \"qwen2.5-coder:7b\", \"path\": \"./vanna_chroma_final_v3\", \"temperature\": 0.0}\n",
    "    analista = SQLAnalyst(config=config_sql)\n",
    "    analista.preparar_agente(\"db.sqlite3\")\n",
    "    \n",
    "    bia = BiaPersona(bairros_validos=analista.bairros)\n",
    "    bateria_de_conferencia(analista, bia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b132339",
   "metadata": {},
   "source": [
    "TESTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe5052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import ollama\n",
    "import sys\n",
    "from rapidfuzz import process\n",
    "from vanna.chromadb import ChromaDB_VectorStore\n",
    "from vanna.ollama import Ollama as VannaOllama\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. ANALISTA SQL (O C√≥digo Robusto que voc√™ forneceu)\n",
    "# ==============================================================================\n",
    "class SQLAnalyst(ChromaDB_VectorStore, VannaOllama):\n",
    "    def __init__(self, config=None):\n",
    "        ChromaDB_VectorStore.__init__(self, config=config)\n",
    "        VannaOllama.__init__(self, config=config)\n",
    "        self.bairros = []\n",
    "        self.entidades = []\n",
    "\n",
    "    def preparar_agente(self, db_path):\n",
    "        \"\"\"Conecta e treina com regras de neg√≥cio blindadas.\"\"\"\n",
    "        print(\"   [SQL] Conectando ao banco e carregando metadados...\")\n",
    "        self.connect_to_sqlite(db_path)\n",
    "        \n",
    "        try:\n",
    "            # Extra√ß√£o de metadados reais para o Fuzzy Match\n",
    "            df_meta = self.run_sql(\"SELECT DISTINCT bairro, rua, especificacao FROM core_imovel\")\n",
    "            self.bairros = [str(x) for x in df_meta['bairro'].dropna().unique().tolist()]\n",
    "            ruas = [str(x) for x in df_meta['rua'].dropna().unique().tolist()]\n",
    "            tipos = [str(x) for x in df_meta['especificacao'].dropna().unique().tolist()]\n",
    "            self.entidades = self.bairros + ruas + tipos\n",
    "        except Exception as e:\n",
    "            print(f\"   [SQL] Aviso: N√£o foi poss√≠vel carregar metadados ({e}).\")\n",
    "\n",
    "        # Treinamento (S√≥ treina se n√£o tiver dados vetoriais)\n",
    "        if self.get_training_data().empty:\n",
    "            print(\"   [SQL] Realizando treinamento inicial do Vanna...\")\n",
    "            self.train(ddl=\"\"\"\n",
    "            CREATE TABLE core_imovel (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT, \n",
    "                titulo VARCHAR(200), \n",
    "                descricao TEXT,\n",
    "                quartos INTEGER, \n",
    "                banheiros INTEGER, \n",
    "                garagem INTEGER, \n",
    "                area DECIMAL, \n",
    "                bairro VARCHAR(100), \n",
    "                rua VARCHAR(100), \n",
    "                preco_aluguel DECIMAL, \n",
    "                preco_iptu DECIMAL, \n",
    "                preco_condominio DECIMAL, \n",
    "                aceita_pets BOOLEAN, \n",
    "                especificacao VARCHAR(100) -- apartamento, casa, kitnet, studio, loft, cobertura\n",
    "            );\n",
    "            \"\"\")\n",
    "\n",
    "            self.train(documentation=f\"\"\"\n",
    "            - Localiza√ß√£o: Juiz de Fora, MG.\n",
    "            - A coluna de tipo de im√≥vel se chama 'especificacao'. NUNCA use 'tipo'.\n",
    "            - REGRA DE PETS: Se o cliente citar 'gato', 'cachorro' ou 'pets', use 'aceita_pets = 1'. \n",
    "            - Use LOWER() apenas para colunas de texto: bairro, rua, especificacao.\n",
    "            - Bairros em JF: {\", \".join(self.bairros)}.\n",
    "            \"\"\")\n",
    "\n",
    "    def normalizar(self, texto):\n",
    "        nfkd = unicodedata.normalize('NFKD', str(texto))\n",
    "        return \"\".join([c for c in nfkd if not unicodedata.combining(c)]).lower().strip()\n",
    "\n",
    "    def fuzzy_cleanup(self, pergunta):\n",
    "        \"\"\"Corrige a pergunta sem duplicar entidades ou alucinar bairros.\"\"\"\n",
    "        if not pergunta: return \"\"\n",
    "        tokens = pergunta.split()\n",
    "        resultado = []\n",
    "        \n",
    "        for t in tokens:\n",
    "            t_norm = self.normalizar(t)\n",
    "            if t_norm.isdigit() or len(t_norm) <= 3:\n",
    "                resultado.append(t); continue\n",
    "            \n",
    "            # Busca correspond√™ncia exata ou aproximada\n",
    "            match = process.extractOne(t_norm, [self.normalizar(e) for e in self.entidades], score_cutoff=88)\n",
    "            if match:\n",
    "                idx = [self.normalizar(e) for e in self.entidades].index(match[0])\n",
    "                entidade_real = self.entidades[idx]\n",
    "                resultado.append(entidade_real)\n",
    "            else:\n",
    "                resultado.append(t)\n",
    "        \n",
    "        pergunta_limpa = \" \".join(resultado)\n",
    "        if any(x in pergunta.lower() for x in [\"gato\", \"cachorro\", \"animal\"]):\n",
    "            pergunta_limpa += \" que aceita pets\"\n",
    "            \n",
    "        return pergunta_limpa\n",
    "\n",
    "    def executar_consulta(self, pergunta):\n",
    "        pergunta_limpa = self.fuzzy_cleanup(pergunta)\n",
    "        print(f\"   [SQL] Query Processada: '{pergunta_limpa}'\")\n",
    "        try:\n",
    "            sql = self.generate_sql(pergunta_limpa)\n",
    "            \n",
    "            # Valida√ß√£o simples\n",
    "            if not sql or \"SELECT\" not in sql.upper():\n",
    "                return None, \"N√£o consegui gerar SQL v√°lido.\"\n",
    "\n",
    "            df = self.run_sql(sql)\n",
    "            return df, sql\n",
    "        except Exception as e:\n",
    "            return None, f\"Erro SQL: {str(e)}\"\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. BIA PERSONA (A \"Boca\" do Chatbot)\n",
    "# ==============================================================================\n",
    "class BiaPersona:\n",
    "    def __init__(self, bairros_validos, model_name='llama3.1'):\n",
    "        self.model = model_name\n",
    "        self.bairros_validos = bairros_validos\n",
    "        \n",
    "    def responder(self, pergunta, df=None, historico=None):\n",
    "        # Cria o contexto de dados\n",
    "        if df is not None and not isinstance(df, str) and not df.empty:\n",
    "            dados_str = df.to_string(index=False)\n",
    "            contexto = f\"RESULTADO DA BUSCA NO BANCO:\\n{dados_str}\\n(Use estes dados para responder. Se o usu√°rio perguntar detalhes, olhe a tabela.)\"\n",
    "        elif isinstance(df, str):\n",
    "            contexto = f\"AVISO DO SISTEMA: {df}\" # Caso de erro\n",
    "        else:\n",
    "            # Contexto vazio ou conversa fiada\n",
    "            contexto = \"Nenhum dado de im√≥vel novo. Apenas converse ou use o hist√≥rico.\"\n",
    "\n",
    "        system_prompt = f\"\"\"\n",
    "        Voc√™ √© a Bia, secret√°ria virtual de uma imobili√°ria em Juiz de Fora.\n",
    "        \n",
    "        INSTRU√á√ïES:\n",
    "        1. Se houver im√≥veis listados em 'RESULTADO DA BUSCA', apresente-os de forma resumida e simp√°tica.\n",
    "        2. Se o resultado for vazio, diga que n√£o encontrou e sugira bairros: {\", \".join(self.bairros_validos[:3])}.\n",
    "        3. Se for apenas conversa (\"Oi\", \"Obrigado\"), seja breve e cordial.\n",
    "        4. N√ÉO invente im√≥veis.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Constr√≥i o prompt final\n",
    "        prompt_final = f\"{system_prompt}\\n\\n{contexto}\\n\\nHist√≥rico recente: {historico}\\n\\nUsu√°rio: {pergunta}\\nBia:\"\n",
    "        \n",
    "        try:\n",
    "            response = ollama.generate(model=self.model, prompt=prompt_final, options={'temperature': 0.3})\n",
    "            return response['response']\n",
    "        except Exception as e:\n",
    "            return f\"Desculpe, tive um erro t√©cnico: {e}\"\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. O ORQUESTRADOR (O \"C√©rebro\" que decide)\n",
    "# ==============================================================================\n",
    "class Orchestrator:\n",
    "    def __init__(self, sql_agent, bia_persona):\n",
    "        self.sql = sql_agent\n",
    "        self.bia = bia_persona\n",
    "        self.historico = [] # Mem√≥ria simples\n",
    "        self.ultimo_df = None # Mem√≥ria de dados\n",
    "\n",
    "    def classificar_intencao(self, texto):\n",
    "        \"\"\"\n",
    "        Usa um modelo r√°pido para decidir se √© SQL (Busca) ou CHAT.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Classifique a frase do usu√°rio em: BUSCA ou CHAT.\n",
    "        \n",
    "        Exemplos:\n",
    "        \"tem apartamento no centro?\" -> BUSCA\n",
    "        \"quanto custa o aluguel?\" -> BUSCA\n",
    "        \"Oi tudo bem?\" -> CHAT\n",
    "        \"Obrigado\" -> CHAT\n",
    "        \"Qual o endere√ßo desse a√≠?\" -> CHAT (Pois refere-se ao contexto anterior, n√£o precisa de SQL novo)\n",
    "        \n",
    "        Frase: \"{texto}\"\n",
    "        Responda APENAS a palavra (BUSCA ou CHAT).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Usando temperatura 0 para ser determin√≠stico\n",
    "            resp = ollama.generate(model=\"qwen2.5-coder:7b\", prompt=prompt, options={'temperature': 0.0})\n",
    "            tag = resp['response'].strip().upper()\n",
    "            if \"BUSCA\" in tag: return \"BUSCA\"\n",
    "            return \"CHAT\"\n",
    "        except:\n",
    "            return \"CHAT\"\n",
    "\n",
    "    def processar(self, texto):\n",
    "        # 1. Identifica Inten√ß√£o\n",
    "        intencao = self.classificar_intencao(texto)\n",
    "        print(f\">>> [ROUTER] Inten√ß√£o: {intencao}\")\n",
    "\n",
    "        dados_para_bia = None\n",
    "\n",
    "        # 2. Executa A√ß√£o\n",
    "        if intencao == \"BUSCA\":\n",
    "            # Passa o texto ORIGINAL para o SQL Analyst (Sem alucina√ß√£o de '2 quartos')\n",
    "            df, sql_log = self.sql.executar_consulta(texto)\n",
    "            self.ultimo_df = df\n",
    "            dados_para_bia = df\n",
    "        else:\n",
    "            # Usa a mem√≥ria anterior se for conversa sobre o im√≥vel\n",
    "            dados_para_bia = self.ultimo_df\n",
    "\n",
    "        # 3. Gera Resposta Final\n",
    "        hist_str = \"\\n\".join([f\"{h['role']}: {h['content']}\" for h in self.historico[-2:]])\n",
    "        resposta = self.bia.responder(texto, df=dados_para_bia, historico=hist_str)\n",
    "\n",
    "        # 4. Atualiza Hist√≥rico\n",
    "        self.historico.append({'role': 'user', 'content': texto})\n",
    "        self.historico.append({'role': 'assistant', 'content': resposta})\n",
    "        \n",
    "        return resposta\n",
    "\n",
    "# ==============================================================================\n",
    "# EXECU√á√ÉO PRINCIPAL\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n--- INICIANDO SISTEMA BIA v6 (Router + SQL Analyst Robusto) ---\")\n",
    "    \n",
    "    # Configura√ß√µes\n",
    "    # QwenCoder √© √≥timo para SQL e Classifica√ß√£o L√≥gica\n",
    "    config_sql = {\"model\": \"qwen2.5-coder:7b\", \"path\": \"./vanna_chroma_final_v6\"}\n",
    "    \n",
    "    # 1. Instancia o Especialista SQL (Seu c√≥digo original)\n",
    "    analista = SQLAnalyst(config=config_sql)\n",
    "    analista.preparar_agente(\"db.sqlite3\")\n",
    "    \n",
    "    # 2. Instancia a Persona (Llama 3.1 para falar bem)\n",
    "    bia_persona = BiaPersona(bairros_validos=analista.bairros, model_name='llama3.1:8B')\n",
    "    \n",
    "    # 3. Instancia o C√©rebro\n",
    "    bot = Orchestrator(analista, bia_persona)\n",
    "    \n",
    "    print(\"\\n‚úÖ Sistema Pronto! (Sem alucina√ß√µes de par√¢metros)\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            txt = input(\"\\nVoc√™: \")\n",
    "            if txt.lower() in ['sair', 'tchau', 'exit']:\n",
    "                print(\"Bia: Tchau! At√© logo.\")\n",
    "                break\n",
    "                \n",
    "            resp = bot.processar(txt)\n",
    "            print(f\"Bia: {resp}\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0969257f",
   "metadata": {},
   "source": [
    "em teste"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
